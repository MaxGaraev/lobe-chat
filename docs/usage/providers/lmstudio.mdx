---
title: Using LM Studio in GDZ.WORKS
description: Learn how to configure and use LM Studio, and run AI models for conversations in GDZ.WORKS through LM Studio.
tags:
  - GDZ.WORKS
  - LM Studio
  - Open Source Model
  - Web UI
---

# Using LM Studio in GDZ.WORKS

[LM Studio](https://lmstudio.ai/) is a platform for testing and running large language models (LLMs), providing an intuitive and easy-to-use interface suitable for developers and AI enthusiasts. It supports deploying and running various open-source LLM models, such as Deepseek or Qwen, on local computers, enabling offline AI chatbot functionality, thereby protecting user privacy and providing greater flexibility.

This document will guide you on how to use LM Studio in GDZ.WORKS:

<Steps>
  ### Step 1: Obtain and Install LM Studio

  - Go to the [LM Studio official website](https://lmstudio.ai/)
  - Choose your platform and download the installation package. LM Studio currently supports MacOS, Windows, and Linux platforms.
  - Follow the prompts to complete the installation and run LM Studio.

  ### Step 2: Search and Download Models

  - Open the `Discover` menu on the left, search for and download the model you want to use.
  - Find a suitable model (such as Deepseek R1) and click download.
  - The download may take some time, please wait patiently for it to complete.

  ### Step 3: Deploy and Run Models

  - Select the downloaded model in the top model selection bar and load the model.

  - Configure the model runtime parameters in the pop-up panel. Refer to the [LM Studio official documentation](https://lmstudio.ai/docs) for detailed parameter settings.

  - Click the `Load Model` button and wait for the model to finish loading and running.

  - Once the model is loaded, you can use it in the chat interface for conversations.

  ### Step 4: Enable Local Service

  - If you want to use the model through other programs, you need to start a local API service. Start the service through the `Developer` panel or the software menu. The LM Studio service starts on port `1234` on your local machine by default.

  - After the local service is started, you also need to enable the `CORS (Cross-Origin Resource Sharing)` option in the service settings so that the model can be used in other programs.

  ### Step 5: Use LM Studio in GDZ.WORKS

  - Visit the `AI Service Provider` interface in GDZ.WORKS's `Application Settings`.

  - Find the settings for `LM Studio` in the list of providers.

  - Open the LM Studio service provider and fill in the API service address.

  <Callout type={"warning"}>
    If your LM Studio is running locally, make sure to turn on `Client Request Mode`.
  </Callout>

  - Add the model you are running in the model list below.
  - Select a Volcano Engine model for your assistant to start the conversation.
</Steps>

Now you can use the model running in LM Studio in GDZ.WORKS for conversations.
